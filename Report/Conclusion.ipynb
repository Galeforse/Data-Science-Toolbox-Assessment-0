{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION\n\n## Project aims\nThe project has, overall, well solidified 2 out of 3 intended purposes, and moderately solidified a third. Programming has evidently played a substantial role in our work, whether it came in the form of transcribing code and converting it into our desired programming language, straight out borrowing code and focusing on understanding it (as well as adding commentaries), or writing new code. We mainly operated in the following languages:\n\n1. Python - via Anaconda and Jupyter notebook\n\n2. R - via RStudio and Jupyter notebook\n\n3. Html\n\nThe quality of programming in this project is not too involved, having mostly focused on portraying data in a \"friendly\" format, i.e. via plots, bars, pies etc. - but also presenting brief explanations of algorithmization processes or methods of deriving the data. Every member who submitted a contribution has moderately explained their programming involved. Regarding experience of assessment, we commonly believe it was a good indicator of how assignments are to be tackled, exception see following point.*\nRegarding collaborative work, while there has been constant communication among team members to ensure everyone's aware of their need for participation, it will be noted that not all members have submitted their work, so the project can be therefore considered incomplete. This is both an individual and circumstantial event. On the individual side, reasons for lack of submissions are unknown. On the circumstantial side ( * ), the project was not centered around a common goal, to the extent that members had to complete each other's works - so it was more individually driven from the start. This, combined with our continuous communication, render the aim of \"collaborative working\" as having been partially met.\n\n## Intended topics\n\n**1) What are the broad types of data?**\nWe have discovered, throughout our research, both quantitative and qualitative data. The main conclusion reached upon considering the two is that certainly both are needed for a thorough analysis of a cyber attack, as often monitorization over several days, weeks or even months is required to detect malicious activity. Broadly, **quantitative** data deals with numbers and things you can measure objectively: dimensions such as height, width, and length. Temperature and humidity. Prices. Area and volume. **Qualitative** data deals with characteristics and descriptors that can't be easily measured, but can be observed subjectivelyâ€”such as smells, tastes, textures, attractiveness, and color. The quantitative aspect plays a more obvious role in our research, as described above, but we'd tend to associate that \"flicker of creativity\" with a more qualitative-driven research. Considering each of our analysis: it would have been worthless collecting all the data we had, were we not able to distinguish patterns, using data analysis knowledge, and rely on what intuitively seems to be happening. Like any other subject, cyber security analysis is a combination of hard work and ingenuity, one without the other being useless.\n\n**2) What are the main types of resource?**\nFor this project, our resources were limited to the most casually accessed one. Checking logs, data-base pattern recognitions, Wireshark captures, traffic monitoring etc. For what resources were used overall - check [here](https://github.com/Galeforse/Data-Science-Toolbox-Assessment-0/blob/main/Report/01-Introduction.ipynb)\nThis question also answers \"What type of problems can the resources solve?\nAre there any generic data science resources that might be applicable? In what sense are they applicable?\", since our team worked on various independent analysis. The problems we have tackled range from credit card fraud, to file transfer protocol (FTP) anomalies and malware activity on external servers. Generic resources we have found useful are plotting tools, which help at better visualizations of the tasks at hand, patterns and obvious anomalies; as well as a great range of either pre-implemented or hand-written functions which aid establishing a model of the malicious activity we encounter. Generally speaking, plotting and mathematical analysis or algorithm pattern seeking seem to be universally reliable tools. \n\n**3) How might the approach be compared to other approaches, and/or applied across different datasets?** \nThere were, as mentioned above, several similarities between our approaches for handling the data presented. One of them would be the \"general resources\" we discussed, of which every member made a great deal of use. However, based on what type of dataset we chose to analyze, both different tools and distinct methods were used. Gabriel analyzed broad datasets and made repeated use of tables and linear regression functions, using basic statistic tools to illustrate the patterns needed to confirm the malicious activity. Matt also used plenty of tables, but also integrated more visuals to his submission - in the same spirit of capturing patterns. Xiao partitioned their work into multiple layers, splitting the dataframe over several columns and making a thorough analysis of each individually. Alex focused more on the method of deriving the analysis, the qualitative research mentioned at point **1**, also making use of Wireshark captures and plotting tools. Overall - this shows that participating members had a great deal of common approaches, but the fundamental differences within the type of datasets each of them tackled made it so they would have to either use some individual tools, or apply methods fit to their analysis, or both.\n\n**4) How is the experience of sharing code via GitHub limiting, and/or enabling?**\nOur team's common consensus about this topic is that it's a mixed bag. On one hand, Github presents a steep learning curve of interaction, mostly due to its unintuitive interface. We strongly believe there is no one who wasn't completely lost the very first time they accessed it! However, Github for desktop made things notably easier for a couple of our members. On the other hand, the experience of sharing code overall would be described as more enabling than limiting. Once you get past the interface issues and the inevitable confusion, it allows a great deal of interaction, such as seeing what everyone is up to, inspiring from each other's progress etc. The general experience with Github was, by the end of it, pleasant."}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}